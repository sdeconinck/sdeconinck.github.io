@article{de2021privacy,
  title={Privacy aware person detection in surveillance data},
  author={De Coninck, Sander and Leroux, Sam and Simoens, Pieter},
  journal={arXiv preprint arXiv:2110.15171},
  year={2021},
  pdf={https://arxiv.org/pdf/2110.15171},
  bibtex_show={true},
  preview={adversarial_obfuscator.png}
}

@article{wang2022opt,
  title={An opt-in framework for privacy protection in audio-based applications},
  author={Wang, Wei-Cheng and De Coninck, Sander and Leroux, Sam and Simoens, Pieter},
  journal={IEEE Pervasive Computing},
  volume={21},
  number={4},
  pages={17--24},
  year={2022},
  publisher={IEEE},
    bibtex_show={true},
    preview={scenario_obs_5.png},
    pdf={https://biblio.ugent.be/publication/01GTV2V5SYTR8N0F5FTCNT3RJ5/file/01GTV2X74D60406THHMJ6TE3A2.pdf}

}

@article{de2022selective,
  title={Selective manipulation of disentangled representations for privacy-aware facial image processing},
  author={De Coninck, Sander and Wang, Wei-Cheng and Leroux, Sam and Simoens, Pieter},
  journal={arXiv preprint arXiv:2208.12632},
  year={2022},
  pdf={https://arxiv.org/pdf/2208.12632},
    bibtex_show={true},
  preview={arch_zerodim.png}

}
@article{cornelissen2025field,
  title={In-Field Mapping of Grape Yield and Quality with Illumination-Invariant Deep Learning},
  author={Cornelissen, Ciem and De Coninck, Sander and Willekens, Axel and Leroux, Sam and Simoens, Pieter},
  journal={IEEE Internet of Things Journal},
  year={2025},
  publisher={IEEE},
    bibtex_show={true},
  preview={iot_paper.png}
}
@article{de2024privacy,
  title={Privacy-preserving visual analysis: training video obfuscation models without sensitive labels},
  author={De Coninck, Sander and Wang, Wei-Cheng and Leroux, Sam and Simoens, Pieter},
  journal={Applied Intelligence},
  volume={54},
  number={8},
  pages={6041--6052},
  year={2024},
  publisher={Springer US New York},
  selected={true}, 
  pdf={https://link.springer.com/content/pdf/10.1007/s10489-024-05489-9.pdf},
  preview={examples.png},
  blog={https://decide.ugent.be/blog/2025-08-01-adversarial-privacy/},
  abstract={Visual analysis tasks, including crowd management, often require resource-intensive machine learning models, posing challenges for deployment on edge hardware. Consequently, cloud computing emerges as a prevalent solution. To address privacy concerns associated with offloading video data to remote cloud platforms, we present a novel approach using adversarial training to develop a lightweight obfuscator neural network. Our method focuses on pedestrian detection as an example of visual analysis, allowing the transformation of video frames on the camera itself to retain only essential information for pedestrian detection while preserving privacy. Importantly, the obfuscated data remains compatible with publicly available object detectors, requiring no modifications or significant loss in accuracy. Additionally, our technique overcomes the common limitation of relying on labeled sensitive attributes for privacy preservation. By demonstrating the inability of pedestrian attribute recognition models to detect attributes in obfuscated videos, we validate the efficacy of our privacy protection method. Our results suggest that this scalable approach holds promise for enabling camera usage in video analytics while upholding personal privacy.
},
  bibtex_show={true},
  poster={Sander_De_Coninck_privacy_aware_video_processing_fair.pdf}

}

@inproceedings{de2024mitigating,
  title={Mitigating Bias Using Model-Agnostic Data Attribution},
  author={De Coninck, Sander and Leroux, Sam and Simoens, Pieter},
  booktitle={2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
  pages={235--243},
  year={2024},
  selected={true},
  pdf={https://openaccess.thecvf.com/content/CVPR2024W/TCV2024/papers/De_Coninck_Mitigating_Bias_Using_Model-Agnostic_Data_Attribution_CVPRW_2024_paper.pdf},
  code={https://github.com/sdeconinck/ModelAgnosticDataAttribution},
  preview={overview_cvpr_fair (2).png},
  abstract={Mitigating bias in machine learning models is a critical endeavor for ensuring fairness and equity. In this paper, we propose a novel approach to address bias by leveraging pixel image attributions to identify and regularize regions of images containing significant information about bias attributes. Our method utilizes a model-agnostic approach to extract pixel attributions by employing a convolutional neural network (CNN) classifier trained on small image patches. By training the classifier to predict a property of the entire image using only a single patch, we achieve region-based attributions that provide insights into the distribution of important information across the image. We propose utilizing these attributions to introduce targeted noise into datasets with confounding attributes that bias the data, thereby constraining neural networks from learning these biases and emphasizing the primary attributes. Our approach demonstrates its efficacy in enabling the training of unbiased classifiers on heavily biased datasets.
},
  bibtex_show={true},
  poster={cvpr24.pdf}

}

@article{wang2025embedding,
  title={Embedding-based pair generation for contrastive representation learning in audio-visual surveillance data},
  author={Wang, Wei-Cheng and De Coninck, Sander and Leroux, Sam and Simoens, Pieter},
  journal={Frontiers in Robotics and AI},
  volume={11},
  pages={1490718},
  year={2025},
  publisher={Frontiers Media SA},
    bibtex_show={true},
  preview={audio_visual_repr.png},
  pdf={https://biblio.ugent.be/publication/01JK86DTW784ZVN1W7XFVFVN2Q/file/01JK86F3WEK3AYK8BMFD22CBMF.pdf}
}

@inproceedings{de2025exploring,
  title={Exploring Correlated Facial Attributes in Text-to-Image Models: Unintended Consequences in Synthetic Face Generation},
  author={De Coninck, Sander and Leroux, Sam and Simoens, Pieter},
  booktitle={Proceedings of the Winter Conference on Applications of Computer Vision (WACV) Workshops},
  pages={1392--1401},
  year={2025},
  selected={true},
  pdf={https://openaccess.thecvf.com/content/WACV2025W/SynRDinBAS/papers/De_Coninck_Exploring_Correlated_Facial_Attributes_in_Text-to-Image_Models_Unintended_Consequences_in_WACVW_2025_paper.pdf}
  ,preview={intro_figure_faces2.png},
  abstract={Text-based face manipulation is a powerful tool for generating and editing facial attributes in synthetic data, particularly for addressing imbalances in biometric datasets and helping to build fair and privacy-aware systems. However, controlling specific attributes remains challenging, as modifying one attribute often leads to unintended changes in others, potentially introducing new biases. In this paper, we investigate the cause of these unintended changes, hypothesizing that they stem from attribute correlations in the training data. By analyzing three face attribute datasets (CelebA, MAAD-Face, FFText-HQ), we identify common patterns of attribute co-occurrence and assess the behavior of three state-of-the-art manipulation models (ManiCLIP, FFCLIP, and DeltaEdit) using attribute classifiers to detect unwanted modifications. We found two types of errors: one where more attributes were altered than intended, and another where changes failed to occur due to dependencies on the original attributes of the face. While we hypothesized that these manipulation issues might correlate with dataset attribute correlations, our analysis using the Matthews Correlation Coefficient found no statistically significant relationships, suggesting that other factors may contribute to these unintended changes. This work can serve as a starting point for further research into the underlying causes of attribute entanglement in face manipulation models, helping to improve understanding and address related challenges.
},
  bibtex_show={true},
  slides={SynRDinBAS2025-14.pdf}

}

@article{DECONINCK2025371,
title = {Enabling Privacy-Aware AI-Based Ergonomic Analysis},
journal = {Procedia CIRP},
volume = {136},
pages = {371-376},
year = {2025},
note = {35th CIRP Design 2025},
issn = {2212-8271},
selected={true},
author = {De Coninck, Sander and Gamba, Emilio and {Van Doninck}, Bart and Bey-Temsamani, Abdellatif and  Leroux, Sam and  Simoens, Pieter},
keywords = {Ergonomic Analysis, Privacy, Human Pose Estimation, Privacy-Aware Machine Learning},
abstract = {Musculoskeletal disorders (MSDs) are a leading cause of injury and productivity loss in the manufacturing industry, incurring substantial economic costs. Ergonomic assessments can mitigate these risks by identifying workplace adjustments that improve posture and reduce strain. Camera-based systems offer a non-intrusive, cost-effective method for continuous ergonomic tracking, but they also raise significant privacy concerns. To address this, we propose a privacy-aware ergonomic assessment framework utilizing machine learning techniques. Our approach employs adversarial training to develop a lightweight neural network that obfuscates video data, preserving only the essential information needed for human pose estimation. This obfuscation ensures compatibility with standard pose estimation algorithms, maintaining high accuracy while protecting privacy. The obfuscated video data is transmitted to a central server, where state-of-the-art keypoint detection algorithms extract body landmarks. Using multi-view integration, 3D keypoints are reconstructed and evaluated with the Rapid Entire Body Assessment (REBA) method. Our system provides a secure, effective solution for ergonomic monitoring in industrial environments, addressing both privacy and workplace safety concerns.},
pdf={https://arxiv.org/pdf/2505.07306},
arxiv={https://arxiv.org/abs/2505.07306},
code={https://github.com/sdeconinck/PrivacyAwareErgo},
preview={adv_obf_ergo (2).png},
  bibtex_show={true},
  slides={PrivacyAwareErgoSlides.pdf}

}